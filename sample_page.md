# Contextualizing new content types

Due to strategic business changes, JSTOR, traditionally a host of academic content like journal articles, was moving to a more diverse multi-content model, including video, audio, and images. Furthermore, this content would no longer come from academic publishers, but individual contributors with potentially laxer standards regarding content curation. 

To meet one of our product OKRs, I conducted exploratory research to understand how our users might contextualize these changes. My goal was to identify complementary information that would be helpful to users when encountering these new types of content. 

**My challenge:** Identify complementary information that would signal the differences in new content to the JSTOR platform, while also maintaining the value of our site’s curation over decades and enriching our overall content offering for users

**My Contribution:** project scope, survey design, study design, protocol development, moderation, data analysis, presentation


## Method and Approach

Put high level graphic of the three stages here. 

### Design Jam

By analyzing prior research, we identified the categories of authority, quality, curation, provenance, and access as being potentially significant information to signal to users in a multi-content environment. The design and research teams then sketched ideas of how we might communicate these five categories on the content page. After the jam, I reviewed all the ideas and developed a list of possible contextual information to signal to users. 

### Survey

Coming out of the design jam, I had a list of over 30 pieces of information that we could communicate to users. We had gone from zero ideas to too many ideas. Therefore, I designed a survey asking users to rank the information most important to them when evaluating content on our website. 

I analyzed over 300 responses to sort the information into three categories: Highest importance, Medium importance, and Lowest importance. After taking into account business needs as well as our technical capacity, I decided upon seven items of contextual information to communicate on our content page and worked with two designers on possible UI elements for signaling the information.

### User interviews and mapping activity (Remote and in-person)

At this point, I started to think through how to test these designs with users. What I really wanted to know was whether the inputs matched the outputs. That is, we had conducted the design jam and developed a list of information to signal based on our internally stated goal of communicating the authority, curation, access, quality, and provenance of content. If we were successful, users should be able to link information found in the UI to these broader overarching concepts. 

I conducted 11 interviews with students, faculty, and researchers: 5 in-person and 6 remote. I started with semi-structured questions, asking participants what information was most important to them when evaluating content for academic work. The second portion of the interview was an interactive mapping exercise, where participants were presented a prototype and asked to place stickers on UI elements that signaled Authority, Curation, Access, Quality, and Provenance, all the while explaining why. 

## Impact

* Internally, our organization felt that these changes to content type would be very jarring for users. But this research showed that users are mostly concerned with relevance, i.e., finding the content most useful to them. Extra information, while occasionally appreciated, was just that—extra. By interrogating this assumption, our organization was able to work on this new strategic initiative with evidence of what users want. 
* I socialized the above learning very widely: Show and Tell, org-wide Lunch and Learn, and ad hoc meetings with Product Managers. As a result, product teams working to redesign follow two principles I developed: 
  1. Content is king! Despite the drastic changes to the types of content on our platform, the content—as opposed to accompanying contextual information—should remain the focus. 
  2. Contextual information should be discoverable on the content page for those who want it, but not distract from the majority of users who are not looking for it



### 2. Assess assumptions on which statistical inference will be based

```javascript
if (isAwesome){
  return true
}
```

### 3. Support the selection of appropriate statistical tools and techniques

<img src="images/dummy_thumbnail.jpg?raw=true"/>

### 4. Provide a basis for further data collection through surveys or experiments

Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. 

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).
